{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seqvanilla.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a456a112e3f4585b800e110097fcbf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8841a9a7b7be4c488f076870d6bb5749",
              "IPY_MODEL_de28ca5c70ed4bdeae15ba2249bb34bb"
            ],
            "layout": "IPY_MODEL_7e614846eb34428ba29b3b0e754e8fba"
          }
        },
        "8841a9a7b7be4c488f076870d6bb5749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acda42c71f2f41358d5bc36e8eae6100",
            "placeholder": "​",
            "style": "IPY_MODEL_b10b768e01d54108940c6258aecdcb7c",
            "value": "4.015 MB of 4.015 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "de28ca5c70ed4bdeae15ba2249bb34bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad92ff0d8d14459bbc07c1d63a092842",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dfc6568b2344e33816616cf4be9bb12",
            "value": 1
          }
        },
        "7e614846eb34428ba29b3b0e754e8fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acda42c71f2f41358d5bc36e8eae6100": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10b768e01d54108940c6258aecdcb7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad92ff0d8d14459bbc07c1d63a092842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dfc6568b2344e33816616cf4be9bb12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipnarayan501/Assignment3/blob/main/seq2seqvanilla.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Seq2Seq model**\n"
      ],
      "metadata": {
        "id": "ovcep9AZbce8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounted the drive and unzip the datset (hindi)"
      ],
      "metadata": {
        "id": "xTR2HNZjboLi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mount to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Unziping dataset\n",
        "zip_path = \"drive/MyDrive/hi.zip\"\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q hi.zip"
      ],
      "metadata": {
        "id": "gyOULlor0N7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662e49c5-6f3a-4c7e-fd6a-3248e4e832a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "configuring wandb"
      ],
      "metadata": {
        "id": "iVBKVF4-oyNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "%pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "lKKQTqJa2dKU",
        "outputId": "281263ce-a25f-4651-af82-f97eb9d99db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 32.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 59.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 45.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libraries"
      ],
      "metadata": {
        "id": "Mc4H7TLapvFn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWbEGfwg0EHz"
      },
      "outputs": [],
      "source": [
        "#Importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.layers import SimpleRNN,LSTM,GRU,Embedding,Dense,Dropout,Input\n",
        "from tensorflow.keras.optimizers import Adam,Nadam\n",
        "from keras import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import pickle\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading** dataset "
      ],
      "metadata": {
        "id": "qsbQeURIqaEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading dataset as dataframe and returning it\n",
        "def load_data(path):\n",
        "    with open(path) as fil:\n",
        "        data = pd.read_csv(fil,sep='\\t',header=None,names=[\"hi\",\"en\",\"\"],skip_blank_lines=True,index_col=None)\n",
        "    data = data[data['hi'].notna()]\n",
        "    data = data[data['en'].notna()]\n",
        "    data = data[['hi','en']]\n",
        "    return data"
      ],
      "metadata": {
        "id": "tH1g08_-0N5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting dataset for train test validation "
      ],
      "metadata": {
        "id": "RprMm_8Aqm1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = load_data(\"/content/hi/lexicons/hi.translit.sampled.train.tsv\")\n",
        "dev = load_data(\"/content/hi/lexicons/hi.translit.sampled.dev.tsv\")\n",
        "test = load_data(\"/content/hi/lexicons/hi.translit.sampled.test.tsv\")"
      ],
      "metadata": {
        "id": "lkRr87yV0OAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting Unique tokens hindi and english language"
      ],
      "metadata": {
        "id": "Lbt4fV7JqtmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_tokenize(data):\n",
        "    english = train['en'].values\n",
        "    hindi = train['hi'].values\n",
        "    hindi = '\\t'+hindi+'\\n'\n",
        "    english_tokens = set()\n",
        "    hindi_tokens = set()\n",
        "    \n",
        "    for x,y in zip(english,hindi):\n",
        "        for ch in x:\n",
        "            english_tokens.add(ch)\n",
        "        for ch in y:\n",
        "            hindi_tokens.add(ch)\n",
        "    english_tokens = sorted(list(english_tokens))\n",
        "    hindi_tokens = sorted(list(hindi_tokens))\n",
        "    return hindi_tokens , english_tokens\n",
        "hindi_tokens , english_tokens = unique_tokenize(train)"
      ],
      "metadata": {
        "id": "iViQ7hPk-vyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping the tokens for hindi and engliish"
      ],
      "metadata": {
        "id": "jhcEbMhIqv23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_map(hindi_tokens , english_tokens):\n",
        "    english_token_map = dict([(ch,i+1) for i,ch in enumerate(english_tokens)])\n",
        "    hindi_token_map = dict([(ch,i+1) for i,ch in enumerate(hindi_tokens)])\n",
        "    #Adding blank space\n",
        "    hindi_token_map[\" \"] = 0\n",
        "    english_token_map[\" \"] = 0\n",
        "    return hindi_token_map, english_token_map\n",
        "\n",
        "hin_token_map, eng_token_map = tokenize_map(hindi_tokens , english_tokens)"
      ],
      "metadata": {
        "id": "t9ZAw7tP-v1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting maximum length "
      ],
      "metadata": {
        "id": "gWRM2T4BrAG2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = train['en'].values\n",
        "y = train['hi'].values\n",
        "y = '\\t'+y+'\\n'\n",
        "\n",
        "#Getting max length\n",
        "max_eng_len = max([len(i) for i in x])\n",
        "max_hin_len = max([len(i) for i in y])"
      ],
      "metadata": {
        "id": "8jgWmEEE-v3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing the datset "
      ],
      "metadata": {
        "id": "ctI_wdaCrxxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(data):\n",
        "    x,y = data['en'].values, data['hi'].values\n",
        "    y = \"\\t\" + y + \"\\n\"\n",
        "    \n",
        "    a = np.zeros((len(x),max_eng_len),dtype=\"float32\")\n",
        "    b = np.zeros((len(y),max_hin_len),dtype=\"float32\")\n",
        "    c = np.zeros((len(y),max_hin_len,len(hindi_tokens)+1),dtype=\"int\")\n",
        "    \n",
        "    \n",
        "    for i,(xx,yy) in enumerate(zip(x,y)):\n",
        "        for j,ch in enumerate(xx):\n",
        "            a[i,j] = eng_token_map[ch]\n",
        "\n",
        "        a[i,j+1:] = eng_token_map[\" \"]\n",
        "        for j,ch in enumerate(yy):\n",
        "            b[i,j] = hin_token_map[ch]\n",
        "\n",
        "            if j>0:\n",
        "                c[i,j-1,hin_token_map[ch]] = 1\n",
        "\n",
        "        b[i,j+1:] = hin_token_map[\" \"]\n",
        "        c[i,j:,hin_token_map[\" \"]] = 1\n",
        "        \n",
        "    return a,b,c"
      ],
      "metadata": {
        "id": "-7f3sFCP1OTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting preprocess train test and validation data\n",
        "trainx, trainxx, trainy = process(train)\n",
        "valx, valxx, valy = process(dev)\n",
        "testx,testxx,testy = process(test)\n",
        "np.random.seed(42)\n",
        "reverse_eng_map = dict([(i,char) for char,i in eng_token_map.items()])\n",
        "reverse_hin_map = dict([(i,char) for char,i in hin_token_map.items()])"
      ],
      "metadata": {
        "id": "HmCHNwFl1OVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating encoder decoder for LSTM , RNN, GRU"
      ],
      "metadata": {
        "id": "75eEXskJskIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(cell = \"LSTM\",units = 32, enc_layers = 1, dec_layers = 1,embedding_dim = 32,dense_size=32,dropout=None):\n",
        "    keras.backend.clear_session()\n",
        "    encoder_inputs = Input(shape=(None,))\n",
        "    encoder_embedding = Embedding(input_dim=len(english_tokens)+1,output_dim = embedding_dim,mask_zero=True)\n",
        "    encoder_context = encoder_embedding(encoder_inputs)\n",
        "    decoder_inputs = Input(shape=(None,))\n",
        "    decoder_embedding = Embedding(input_dim = len(hindi_tokens)+1,output_dim = embedding_dim,mask_zero=True)\n",
        "    decoder_context = decoder_embedding(decoder_inputs)\n",
        "  \n",
        "    if cell == \"LSTM\":\n",
        "        encoder_prev = [LSTM(units,return_sequences=True) for i in range(enc_layers-1)]\n",
        "        encoder_fin = LSTM(units,return_state=True)\n",
        "        temp = encoder_context\n",
        "        for lay in encoder_prev:\n",
        "            temp = lay(temp)\n",
        "            if dropout is not None:\n",
        "                temp = Dropout(dropout)(temp)\n",
        "            \n",
        "        _, state_h,state_c = encoder_fin(temp)\n",
        "        encoder_states = [state_h,state_c]\n",
        "        \n",
        "        decoder = [LSTM(units,return_sequences=True,return_state=True) for i in range(dec_layers)]\n",
        "        \n",
        "        temp,sh,sc = decoder[0](decoder_context,initial_state=encoder_states)\n",
        "        for i in range(1,dec_layers):\n",
        "            temp,sh,sc = decoder[i](temp,initial_state=encoder_states)\n",
        "\n",
        "    elif cell == \"GRU\":\n",
        "        encoder_prev = [GRU(units,return_sequences=True) for i in range(enc_layers-1)]\n",
        "        encoder_fin = GRU(units,return_state=True)\n",
        "        temp = encoder_context\n",
        "        for lay in encoder_prev:\n",
        "            temp = lay(temp)\n",
        "            if dropout is not None:\n",
        "                temp = Dropout(dropout)(temp)\n",
        "            \n",
        "        _, state = encoder_fin(temp)\n",
        "        encoder_states = state\n",
        "        \n",
        "        decoder = [GRU(units,return_sequences=True,return_state=True) for i in range(dec_layers)]\n",
        "        \n",
        "        temp,s = decoder[0](decoder_context,initial_state=state)\n",
        "        for i in range(1,dec_layers):\n",
        "            temp,s = decoder[i](temp,initial_state=state)\n",
        "\n",
        "    elif cell == \"RNN\":\n",
        "        encoder_prev = [SimpleRNN(units,return_sequences=True) for i in range(enc_layers-1)]\n",
        "        encoder_fin = SimpleRNN(units,return_state=True)\n",
        "        temp = encoder_context\n",
        "        for lay in encoder_prev:\n",
        "            temp = lay(temp)\n",
        "            if dropout is not None:\n",
        "                temp = Dropout(dropout)(temp)\n",
        "            \n",
        "        _, state = encoder_fin(temp)\n",
        "        encoder_states = state\n",
        "        \n",
        "        decoder = [SimpleRNN(units,return_sequences=True,return_state=True) for i in range(dec_layers)]\n",
        "        \n",
        "        temp,s = decoder[0](decoder_context,initial_state=state)\n",
        "        for i in range(1,dec_layers):\n",
        "            temp,s = decoder[i](temp,initial_state=state)\n",
        "       \n",
        "\n",
        "            \n",
        "        \n",
        "    dense_lay1 = Dense(dense_size,activation='relu')\n",
        "    pre_out = dense_lay1(temp)\n",
        "    dense_lay2 = Dense(len(hindi_tokens)+1,activation = 'softmax')\n",
        "    final_output = dense_lay2(pre_out)\n",
        "    \n",
        "    train = Model([encoder_inputs,decoder_inputs],final_output)\n",
        "    \n",
        "    encoder_model = Model(encoder_inputs,encoder_states)\n",
        "    \n",
        "    if cell == \"LSTM\":\n",
        "        state_inputs = []\n",
        "        state_outputs = []\n",
        "        \n",
        "        decoder_input_h = Input(shape=(units,))\n",
        "        decoder_input_c = Input(shape=(units,))\n",
        "        temp,sh,sc = decoder[0](decoder_context,initial_state = [decoder_input_h,decoder_input_c])\n",
        "        state_inputs += [decoder_input_h,decoder_input_c]\n",
        "        state_outputs += [sh,sc]\n",
        "                                                                  \n",
        "        for i in range(1,dec_layers):\n",
        "            decoder_input_h = Input(shape=(units,))\n",
        "            decoder_input_c = Input(shape=(units,))\n",
        "            temp,sh,sc = decoder[i](temp,initial_state = [decoder_input_h,decoder_input_c])\n",
        "            state_inputs += [decoder_input_h,decoder_input_c]\n",
        "            state_outputs += [sh,sc]\n",
        "            \n",
        "        decoder_input_pass = [decoder_inputs] + state_inputs\n",
        "    elif cell == \"GRU\":\n",
        "        state_inputs = []\n",
        "        state_outputs = []\n",
        "        \n",
        "        state_input = Input(shape=(units,))\n",
        "        temp,s = decoder[0](decoder_context,initial_state = state_input)\n",
        "        state_inputs.append(state_input)\n",
        "        state_outputs.append(s)\n",
        "                                                                  \n",
        "        for i in range(1,dec_layers):\n",
        "            state_input = Input(shape=(units,))\n",
        "            temp,s = decoder[i](temp,initial_state = state_input)\n",
        "            state_inputs.append(state_input)\n",
        "            state_outputs.append(s)\n",
        "            \n",
        "        decoder_input_pass = [decoder_inputs] + state_inputs\n",
        "\n",
        "    elif cell == \"RNN\":\n",
        "        state_inputs = []\n",
        "        state_outputs = []\n",
        "        \n",
        "        state_input = Input(shape=(units,))\n",
        "        temp,s = decoder[0](decoder_context,initial_state = state_input)\n",
        "        state_inputs.append(state_input)\n",
        "        state_outputs.append(s)\n",
        "                                                                  \n",
        "        for i in range(1,dec_layers):\n",
        "            state_input = Input(shape=(units,))\n",
        "            temp,s = decoder[i](temp,initial_state = state_input)\n",
        "            state_inputs.append(state_input)\n",
        "            state_outputs.append(s)\n",
        "            \n",
        "        decoder_input_pass = [decoder_inputs] + state_inputs\n",
        "        \n",
        "\n",
        "\n",
        "    pre_out = dense_lay1(temp)\n",
        "    final_output = dense_lay2(pre_out)\n",
        "    \n",
        "    decoder_model = Model(decoder_input_pass, [final_output]+state_outputs)\n",
        "    \n",
        "    return train,encoder_model,decoder_model"
      ],
      "metadata": {
        "id": "pMjBcN1b1l1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "configuring wandb"
      ],
      "metadata": {
        "id": "KMuodZofs20f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "%pip install wandb -q\n",
        "import wandb\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwkZtK_21l3g",
        "outputId": "26767f7b-62fd-4b27-8ee2-3c04d14e87ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdipnarayan501\u001b[0m (\u001b[33mfdl-moni_dip\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    # Default values for hyper-parameters we're going to sweep over\n",
        "    config_defaults = {\n",
        "        'learning_rate': 1e-2,\n",
        "        'dense_size': 128,\n",
        "        'units': 128,\n",
        "        'cell': 'LSTM',\n",
        "        'embedding_dim': 64,\n",
        "        'enc_layers': 1,\n",
        "        'dec_layers': 1,\n",
        "        'dropout': 0.,\n",
        "        'batch_size': 64\n",
        "    }\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init(config=config_defaults)\n",
        "    \n",
        "    config = wandb.config\n",
        "    \n",
        "    dense_size=config.dense_size\n",
        "    cell = config.cell\n",
        "    dropout = config.dropout\n",
        "    enc_layers=config.enc_layers\n",
        "    dec_layers=config.dec_layers\n",
        "    embedding_dim = config.embedding_dim\n",
        "    units = config.units\n",
        "\n",
        "    learning_rate = config.learning_rate\n",
        "    batch_size = config.batch_size\n",
        "                                \n",
        "\n",
        "    # Displaying hyperparameters\n",
        "    run_name = \"cell_{}_enc_lay_{}_dec_lay_{}_units_{}_embd_{}_dp_{}_lr_{}_ds_{}_bs_{}\".format(cell, enc_layers, dec_layers,units,embedding_dim, dropout, learning_rate, dense_size,batch_size)\n",
        "    print(run_name)    \n",
        "    # Config is a variable\n",
        "    train,enc,dec = build_model(units=units,\n",
        "                                dense_size=dense_size,\n",
        "                                enc_layers=enc_layers,\n",
        "                                dec_layers=dec_layers,\n",
        "                                cell = cell,\n",
        "                                dropout = dropout,\n",
        "                                embedding_dim = embedding_dim)\n",
        "    train.compile(optimizer = Adam(learning_rate= learning_rate),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "    \n",
        "    # Early Stopping \n",
        "    earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
        "\n",
        "    # To save the model with best validation accuracy\n",
        "    checkpoint = ModelCheckpoint('bestmodel.h5', monitor='val_accuracy', mode='max', verbose=0, save_best_only=True)\n",
        "    train.fit([trainx,trainxx],trainy,\n",
        "             batch_size=batch_size,\n",
        "             validation_data = ([valx,valxx],valy),\n",
        "             epochs=10,\n",
        "             callbacks=[WandbCallback(), earlyStopping,checkpoint])\n",
        "\n",
        "    print(\"model training done\")\n",
        "    wandb.run.name = run_name\n",
        "    wandb.run.save()\n",
        "    return train"
      ],
      "metadata": {
        "id": "iTWPvuWC13eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sweep configuration "
      ],
      "metadata": {
        "id": "fYXObPets_2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'  \n",
        "    },\n",
        "    'parameters': {\n",
        "        'learning_rate': {\n",
        "            'values': [0.01, 0.001]\n",
        "        },\n",
        "        'dense_size': {\n",
        "            'values': [64,128,512]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.0,0.2,0.4]\n",
        "        },\n",
        "        'units': {\n",
        "            'values': [64,128,256]\n",
        "        },\n",
        "          'batch_size': {\n",
        "            'values': [64,128,256]\n",
        "        },\n",
        "        'cell': {\n",
        "            'values': [\"LSTM\",\"GRU\",\"RNN\"]\n",
        "        },\n",
        "        'embedding_size': {\n",
        "            'values': [64,128,256]\n",
        "        },\n",
        "        'enc_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        'dec_layers': {\n",
        "            'values': [1,2,3]\n",
        "        },\n",
        "        \n",
        "    }\n",
        "}\n",
        "\n",
        "#sweep_id = wandb.sweep(sweep_config, entity=\"fdl-moni_dip\", project=\"s2s_vannila\")"
      ],
      "metadata": {
        "id": "9AwMAJwNK6gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sweep id "
      ],
      "metadata": {
        "id": "ojD_bqp_tG35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id = '152q0uoh'\n",
        "wandb.agent(id, train,entity=\"fdl-moni_dip\", project=\"s2s_vannila\", count=1)"
      ],
      "metadata": {
        "id": "ki-Mnt-i13lC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1a456a112e3f4585b800e110097fcbf4",
            "8841a9a7b7be4c488f076870d6bb5749",
            "de28ca5c70ed4bdeae15ba2249bb34bb",
            "7e614846eb34428ba29b3b0e754e8fba",
            "acda42c71f2f41358d5bc36e8eae6100",
            "b10b768e01d54108940c6258aecdcb7c",
            "ad92ff0d8d14459bbc07c1d63a092842",
            "7dfc6568b2344e33816616cf4be9bb12"
          ]
        },
        "outputId": "70158955-9874-4cfb-badb-48e4b0ce0d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gsx5sp73 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tunits: 256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220504_061424-gsx5sp73</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/fdl-moni_dip/s2s_vannila/runs/gsx5sp73\" target=\"_blank\">silvery-sweep-63</a></strong> to <a href=\"https://wandb.ai/fdl-moni_dip/s2s_vannila\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/fdl-moni_dip/s2s_vannila/sweeps/152q0uoh\" target=\"_blank\">https://wandb.ai/fdl-moni_dip/s2s_vannila/sweeps/152q0uoh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cell_RNN_enc_lay_2_dec_lay_1_units_256_embd_64_dp_0.2_lr_0.001_ds_128_bs_128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "346/346 [==============================] - 108s 297ms/step - loss: 0.9009 - accuracy: 0.3970 - val_loss: 0.6746 - val_accuracy: 0.5140 - _timestamp: 1651644979.0000 - _runtime: 114.0000\n",
            "Epoch 2/10\n",
            "346/346 [==============================] - 88s 254ms/step - loss: 0.5906 - accuracy: 0.5724 - val_loss: 0.4699 - val_accuracy: 0.6310 - _timestamp: 1651645067.0000 - _runtime: 202.0000\n",
            "Epoch 3/10\n",
            "346/346 [==============================] - 75s 215ms/step - loss: 0.4367 - accuracy: 0.6656 - val_loss: 0.3799 - val_accuracy: 0.6984 - _timestamp: 1651645141.0000 - _runtime: 276.0000\n",
            "Epoch 4/10\n",
            "346/346 [==============================] - 80s 232ms/step - loss: 0.3657 - accuracy: 0.7136 - val_loss: 0.3376 - val_accuracy: 0.7263 - _timestamp: 1651645222.0000 - _runtime: 357.0000\n",
            "Epoch 5/10\n",
            "346/346 [==============================] - 74s 215ms/step - loss: 0.3230 - accuracy: 0.7448 - val_loss: 0.3111 - val_accuracy: 0.7456 - _timestamp: 1651645296.0000 - _runtime: 431.0000\n",
            "Epoch 6/10\n",
            "346/346 [==============================] - 74s 215ms/step - loss: 0.2952 - accuracy: 0.7647 - val_loss: 0.2973 - val_accuracy: 0.7553 - _timestamp: 1651645370.0000 - _runtime: 505.0000\n",
            "Epoch 7/10\n",
            "346/346 [==============================] - 74s 215ms/step - loss: 0.2722 - accuracy: 0.7819 - val_loss: 0.2840 - val_accuracy: 0.7682 - _timestamp: 1651645445.0000 - _runtime: 580.0000\n",
            "Epoch 8/10\n",
            "346/346 [==============================] - 74s 215ms/step - loss: 0.2567 - accuracy: 0.7936 - val_loss: 0.2740 - val_accuracy: 0.7789 - _timestamp: 1651645519.0000 - _runtime: 654.0000\n",
            "Epoch 9/10\n",
            "346/346 [==============================] - 75s 216ms/step - loss: 0.2416 - accuracy: 0.8051 - val_loss: 0.2682 - val_accuracy: 0.7808 - _timestamp: 1651645594.0000 - _runtime: 729.0000\n",
            "Epoch 10/10\n",
            "346/346 [==============================] - 74s 215ms/step - loss: 0.2324 - accuracy: 0.8114 - val_loss: 0.2671 - val_accuracy: 0.7811 - _timestamp: 1651645668.0000 - _runtime: 803.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model training done\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='4.004 MB of 4.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a456a112e3f4585b800e110097fcbf4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▄▆▆▇▇████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.81139</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.26711</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.23244</td></tr><tr><td>val_accuracy</td><td>0.7811</td></tr><tr><td>val_loss</td><td>0.26711</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">silvery-sweep-63</strong>: <a href=\"https://wandb.ai/fdl-moni_dip/s2s_vannila/runs/gsx5sp73\" target=\"_blank\">https://wandb.ai/fdl-moni_dip/s2s_vannila/runs/gsx5sp73</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220504_061424-gsx5sp73/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retraining model with best Parameters \n"
      ],
      "metadata": {
        "id": "ugaaua6FMfxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train,enc,dec = build_model(units=256,dense_size=512,enc_layers=2,dec_layers=3,cell = \"GRU\", embedding_dim = 64)\n",
        "train.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.h5',monitor='val_accuracy',mode='max',save_best_only=True,verbose=1)\n",
        "train.fit([trainx,trainxx],trainy,\n",
        "         batch_size=128,\n",
        "         validation_data=([valx,valxx],valy),\n",
        "         epochs=10,\n",
        "          callbacks = [checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhgP2VB8uPau",
        "outputId": "673f9735-44c5-4bcb-bbfe-99adebf86093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.9571 - accuracy: 0.3476\n",
            "Epoch 1: val_accuracy improved from -inf to 0.49960, saving model to best_model.h5\n",
            "346/346 [==============================] - 320s 867ms/step - loss: 0.9571 - accuracy: 0.3476 - val_loss: 0.6602 - val_accuracy: 0.4996\n",
            "Epoch 2/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.6361\n",
            "Epoch 2: val_accuracy improved from 0.49960 to 0.73006, saving model to best_model.h5\n",
            "346/346 [==============================] - 289s 835ms/step - loss: 0.4859 - accuracy: 0.6361 - val_loss: 0.3358 - val_accuracy: 0.7301\n",
            "Epoch 3/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.7791\n",
            "Epoch 3: val_accuracy improved from 0.73006 to 0.80314, saving model to best_model.h5\n",
            "346/346 [==============================] - 299s 864ms/step - loss: 0.2816 - accuracy: 0.7791 - val_loss: 0.2399 - val_accuracy: 0.8031\n",
            "Epoch 4/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.8355\n",
            "Epoch 4: val_accuracy improved from 0.80314 to 0.83325, saving model to best_model.h5\n",
            "346/346 [==============================] - 289s 835ms/step - loss: 0.2060 - accuracy: 0.8355 - val_loss: 0.2024 - val_accuracy: 0.8332\n",
            "Epoch 5/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.8661\n",
            "Epoch 5: val_accuracy improved from 0.83325 to 0.84274, saving model to best_model.h5\n",
            "346/346 [==============================] - 289s 837ms/step - loss: 0.1656 - accuracy: 0.8661 - val_loss: 0.1897 - val_accuracy: 0.8427\n",
            "Epoch 6/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.8872\n",
            "Epoch 6: val_accuracy improved from 0.84274 to 0.85381, saving model to best_model.h5\n",
            "346/346 [==============================] - 291s 840ms/step - loss: 0.1392 - accuracy: 0.8872 - val_loss: 0.1784 - val_accuracy: 0.8538\n",
            "Epoch 7/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.9026\n",
            "Epoch 7: val_accuracy improved from 0.85381 to 0.85874, saving model to best_model.h5\n",
            "346/346 [==============================] - 289s 835ms/step - loss: 0.1190 - accuracy: 0.9026 - val_loss: 0.1742 - val_accuracy: 0.8587\n",
            "Epoch 8/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9168\n",
            "Epoch 8: val_accuracy improved from 0.85874 to 0.86517, saving model to best_model.h5\n",
            "346/346 [==============================] - 287s 831ms/step - loss: 0.1018 - accuracy: 0.9168 - val_loss: 0.1699 - val_accuracy: 0.8652\n",
            "Epoch 9/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.9275\n",
            "Epoch 9: val_accuracy did not improve from 0.86517\n",
            "346/346 [==============================] - 284s 822ms/step - loss: 0.0878 - accuracy: 0.9275 - val_loss: 0.1748 - val_accuracy: 0.8631\n",
            "Epoch 10/10\n",
            "346/346 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9363\n",
            "Epoch 10: val_accuracy improved from 0.86517 to 0.86618, saving model to best_model.h5\n",
            "346/346 [==============================] - 286s 826ms/step - loss: 0.0767 - accuracy: 0.9363 - val_loss: 0.1788 - val_accuracy: 0.8662\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61e62dea90>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining inference model and getting prediction\n",
        "def inference(inp,dec_layers,cell=\"LSTM\"):\n",
        "    statess = enc.predict(inp)\n",
        "    target_seq = np.zeros((inp.shape[0],1))\n",
        "    target_seq[:,0] = hin_token_map[\"\\t\"]\n",
        "    \n",
        "    states = []\n",
        "    \n",
        "    if cell == \"LSTM\":\n",
        "        for c in range(dec_layers):\n",
        "            states += [statess[0],statess[1]]\n",
        "            \n",
        "    else:\n",
        "        for c in range(dec_layers):\n",
        "            states += [statess]\n",
        "            \n",
        "    ans = np.zeros((inp.shape[0],max_hin_len))\n",
        "    \n",
        "    for i in range(max_hin_len):\n",
        "        output = dec.predict([target_seq]+states,batch_size=64)\n",
        "        ans[:,i] = np.argmax(output[0][:,-1,:],axis=1)\n",
        "        target_seq[:,0] = ans[:,i]\n",
        "        states = output[1:]\n",
        "        \n",
        "    return ans"
      ],
      "metadata": {
        "id": "uWs1m1isbDTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vtYta8g_Zhce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Predicting test word\n",
        "prediction = inference(testx,3,cell=\"GRU\")\n",
        "\n",
        "#printing 10 sample outputs\n",
        "for i in range(10):\n",
        "    idx = np.random.choice(testx.shape[0])\n",
        "    orig = \"\"\n",
        "    for ch in testx[idx]:\n",
        "        orig += reverse_eng_map[ch]\n",
        "        if reverse_eng_map[ch] == \"\\n\":\n",
        "            break\n",
        "        \n",
        "    deco = \"\"\n",
        "    for ch in prediction[idx]:\n",
        "        deco += reverse_hin_map[ch]\n",
        "        if reverse_hin_map[ch] == \"\\n\":\n",
        "            break\n",
        "        \n",
        "    print(\"Input :\",orig)\n",
        "    print(\"Output:\", deco)\n",
        "    print(\"********\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b2Fc9D8QHaQ",
        "outputId": "a6460c32-9b5c-4381-baef-32230f95f128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : kajoo               \n",
            "Output: काजू\n",
            "\n",
            "********\n",
            "Input : purjon              \n",
            "Output: पूर्जों\n",
            "\n",
            "********\n",
            "Input : peratrupers         \n",
            "Output: पर्टरपर्स\n",
            "\n",
            "********\n",
            "Input : chaupal             \n",
            "Output: चौपाल\n",
            "\n",
            "********\n",
            "Input : raak                \n",
            "Output: राक\n",
            "\n",
            "********\n",
            "Input : saleeb              \n",
            "Output: सलीब\n",
            "\n",
            "********\n",
            "Input : borivali            \n",
            "Output: बोरीवाली\n",
            "\n",
            "********\n",
            "Input : untees              \n",
            "Output: अन्टीस\n",
            "\n",
            "********\n",
            "Input : chand               \n",
            "Output: चांड\n",
            "\n",
            "********\n",
            "Input : farukhnagar         \n",
            "Output: फरुक्चानगार\n",
            "\n",
            "********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting output words\n",
        "output_words = []\n",
        "for i in range(testx.shape[0]):\n",
        "    idx = i    \n",
        "    decode = \"\"\n",
        "    for ch in prediction[idx]:\n",
        "        decode += reverse_hin_map[ch]\n",
        "        if reverse_hin_map[ch] == \"\\n\":\n",
        "            break\n",
        "\n",
        "    output_words.append(decode)\n",
        "\n",
        "print(len(output_words))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i67xjsNKfGB1",
        "outputId": "3f7f160b-a6df-4cb9-a960-7af5f760abac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving ouput as prediction_vanilla,csv from dataframe\n",
        "pred = pd.DataFrame(output_words)\n",
        "pred1 = pred.replace('\\\\n','', regex=True)\n",
        "final_pred = pred1.replace('\\\\t','', regex=True)\n",
        "\n",
        "\n",
        "test['pred_vanilla'] = final_pred.values\n",
        "test.rename(columns = {'hi':'target', 'en':'input'}, inplace = True)\n",
        "test.to_csv('prediction_vanilla.csv', sep='\\t', encoding='utf-8')\n"
      ],
      "metadata": {
        "id": "wY8tdPhNpyup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "kVEuYm41pyx8",
        "outputId": "853fa4d5-d8e7-477d-8496-a31b4b324be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target     input pred_vanilla\n",
              "0        अंक       ank          अंक\n",
              "1        अंक      anka         अंका\n",
              "2      अंकित     ankit        अंकित\n",
              "3      अंकों    anakon       अनाकों\n",
              "4      अंकों    ankhon        अंखों\n",
              "5      अंकों     ankon        अंकों\n",
              "6      अंकोर    angkor       अंगकोर\n",
              "7      अंकोर     ankor         अंकर\n",
              "8     अंगारक  angaarak       अंगारक\n",
              "9     अंगारक   angarak       अंगारक\n",
              "10  अंग्रज़ी   angraji      अंग्रजी\n",
              "11  अंग्रज़ी   angreji      अंग्रजी\n",
              "12  अंग्रज़ी    angrzi      अंग्रजी\n",
              "13      अंतः     antah        अंताह\n",
              "14      अंतः    antaha       अंताहा"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52e13701-1f74-4082-9ba1-d3f697ae11ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>input</th>\n",
              "      <th>pred_vanilla</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>अंक</td>\n",
              "      <td>ank</td>\n",
              "      <td>अंक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>अंक</td>\n",
              "      <td>anka</td>\n",
              "      <td>अंका</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>अंकित</td>\n",
              "      <td>ankit</td>\n",
              "      <td>अंकित</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>अंकों</td>\n",
              "      <td>anakon</td>\n",
              "      <td>अनाकों</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>अंकों</td>\n",
              "      <td>ankhon</td>\n",
              "      <td>अंखों</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>अंकों</td>\n",
              "      <td>ankon</td>\n",
              "      <td>अंकों</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>अंकोर</td>\n",
              "      <td>angkor</td>\n",
              "      <td>अंगकोर</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>अंकोर</td>\n",
              "      <td>ankor</td>\n",
              "      <td>अंकर</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>अंगारक</td>\n",
              "      <td>angaarak</td>\n",
              "      <td>अंगारक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>अंगारक</td>\n",
              "      <td>angarak</td>\n",
              "      <td>अंगारक</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>अंग्रज़ी</td>\n",
              "      <td>angraji</td>\n",
              "      <td>अंग्रजी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>अंग्रज़ी</td>\n",
              "      <td>angreji</td>\n",
              "      <td>अंग्रजी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>अंग्रज़ी</td>\n",
              "      <td>angrzi</td>\n",
              "      <td>अंग्रजी</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>अंतः</td>\n",
              "      <td>antah</td>\n",
              "      <td>अंताह</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>अंतः</td>\n",
              "      <td>antaha</td>\n",
              "      <td>अंताहा</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52e13701-1f74-4082-9ba1-d3f697ae11ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52e13701-1f74-4082-9ba1-d3f697ae11ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52e13701-1f74-4082-9ba1-d3f697ae11ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test accuracy by matching exact string\n",
        "def test_accuracy(pred): \n",
        "  acc = 0\n",
        "\n",
        "  for i,pr in enumerate(pred):\n",
        "      fl = 1\n",
        "      for j,ch in enumerate(pr):\n",
        "          if ch != np.argmax(testy[i,j,:]):\n",
        "              fl = 0\n",
        "              break\n",
        "          if ch == hin_token_map[\"\\n\"]:\n",
        "              break\n",
        "              \n",
        "      if fl==1:\n",
        "          acc+=1\n",
        "    \n",
        "  return (acc/len(pred))*100\n",
        "\n",
        "\n",
        "\n",
        "print(\"Test accuracy with best parameters of s2s_without attention  \", test_accuracy(prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMFO5BnLQH2T",
        "outputId": "a251a172-835f-40ae-9e3d-9f2bc6440cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy with best parameters of s2s_without attention   34.606841403820525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nQaXUweKajCV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}